diff --git a/clvk/src/CMakeLists.txt b/clvk/src/CMakeLists.txt
index 46a44a1..cac6069 100644
--- a/clvk/src/CMakeLists.txt
+++ b/clvk/src/CMakeLists.txt
@@ -52,6 +52,7 @@ add_library(OpenCL-objects OBJECT
   memory.cpp
   program.cpp
   queue.cpp
+  semaphore.cpp
   sha1.cpp
   tracing.cpp
   unit.cpp
diff --git a/clvk/src/device.cpp b/clvk/src/device.cpp
index ce5e83a..7108d98 100644
--- a/clvk/src/device.cpp
+++ b/clvk/src/device.cpp
@@ -47,6 +47,8 @@ void cvk_device::init_vulkan_properties(VkInstance instance) {
         VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PCI_BUS_INFO_PROPERTIES_EXT;
     m_subgroup_properties.sType =
         VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_PROPERTIES;
+    m_timeline_semaphore_properties.sType =
+        VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_PROPERTIES;
 
 #define VER_EXT_PROP(ver, ext, prop)                                           \
     {ver, ext, reinterpret_cast<VkBaseOutStructure*>(&prop)}
@@ -61,6 +63,9 @@ void cvk_device::init_vulkan_properties(VkInstance instance) {
                          m_pci_bus_info_properties),
             VER_EXT_PROP(VK_MAKE_VERSION(1, 1, 0), nullptr,
                          m_subgroup_properties),
+            VER_EXT_PROP(VK_MAKE_VERSION(1, 2, 0),
+                         VK_KHR_TIMELINE_SEMAPHORE_EXTENSION_NAME,
+                         m_timeline_semaphore_properties),
         };
 #undef VER_EXT_PROP
 
@@ -217,6 +222,7 @@ bool cvk_device::init_extensions() {
         VK_KHR_SHADER_FLOAT_CONTROLS_EXTENSION_NAME,
         VK_KHR_VULKAN_MEMORY_MODEL_EXTENSION_NAME,
         VK_EXT_DESCRIPTOR_INDEXING_EXTENSION_NAME,
+        VK_KHR_TIMELINE_SEMAPHORE_EXTENSION_NAME,
     };
 
     if (m_properties.apiVersion < VK_MAKE_VERSION(1, 2, 0)) {
@@ -268,6 +274,8 @@ void cvk_device::init_features(VkInstance instance) {
         VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_EXTENDED_TYPES_FEATURES_KHR;
     m_features_vulkan_memory_model.sType =
         VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES;
+    m_features_timeline_semaphore.sType =
+        VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_FEATURES;
 
     std::vector<std::tuple<uint32_t, const char*, VkBaseOutStructure*>>
         coreversion_extension_features = {
@@ -294,6 +302,9 @@ void cvk_device::init_features(VkInstance instance) {
             VER_EXT_FEAT(VK_MAKE_VERSION(1, 2, 0),
                          VK_KHR_VULKAN_MEMORY_MODEL_EXTENSION_NAME,
                          m_features_vulkan_memory_model),
+            VER_EXT_FEAT(VK_MAKE_VERSION(1, 2, 0),
+                         VK_KHR_TIMELINE_SEMAPHORE_EXTENSION_NAME,
+                         m_features_timeline_semaphore),
 #undef VER_EXT_FEAT
         };
 
@@ -340,6 +351,8 @@ void cvk_device::init_features(VkInstance instance) {
     cvk_info(
         "subgroup extended types: %d",
         m_features_shader_subgroup_extended_types.shaderSubgroupExtendedTypes);
+    cvk_info("timeline semaphore: %d",
+             m_features_timeline_semaphore.timelineSemaphore);
 
     // Selectively enable core features.
     if (supported_features.features.shaderInt16) {
diff --git a/clvk/src/device.hpp b/clvk/src/device.hpp
index 05ca4b0..5eebd12 100644
--- a/clvk/src/device.hpp
+++ b/clvk/src/device.hpp
@@ -431,6 +431,15 @@ struct cvk_device : public _cl_device_id,
 
     CHECK_RETURN bool has_timer_support() const { return m_has_timer_support; }
 
+    CHECK_RETURN bool has_timeline_semaphore_support() const {
+        return m_features_timeline_semaphore.timelineSemaphore;
+    }
+
+    CHECK_RETURN uint32_t maxTimelineSemaphoreValueDifference() const {
+        return m_timeline_semaphore_properties
+            .maxTimelineSemaphoreValueDifference;
+    }
+
     CHECK_RETURN cl_int get_device_host_timer(cl_ulong* dev_ts,
                                               cl_ulong* host_ts) const;
     cl_ulong device_timer_to_host(cl_ulong dev, cl_ulong sync_dev,
@@ -538,6 +547,7 @@ private:
     VkPhysicalDeviceIDPropertiesKHR m_device_id_properties;
     VkPhysicalDeviceSubgroupProperties m_subgroup_properties{};
     VkPhysicalDevicePCIBusInfoPropertiesEXT m_pci_bus_info_properties;
+    VkPhysicalDeviceTimelineSemaphoreProperties m_timeline_semaphore_properties;
     // Vulkan features
     VkPhysicalDeviceFeatures2 m_features{};
     VkPhysicalDeviceVariablePointerFeatures m_features_variable_pointer{};
@@ -550,6 +560,7 @@ private:
         m_features_shader_subgroup_extended_types{};
     VkPhysicalDeviceVulkanMemoryModelFeaturesKHR
         m_features_vulkan_memory_model{};
+    VkPhysicalDeviceTimelineSemaphoreFeatures m_features_timeline_semaphore{};
 
     VkDevice m_dev;
     std::vector<const char*> m_vulkan_device_extensions;
diff --git a/clvk/src/event.cpp b/clvk/src/event.cpp
index 969b321..cfe1c07 100644
--- a/clvk/src/event.cpp
+++ b/clvk/src/event.cpp
@@ -32,13 +32,21 @@ cvk_event_command::cvk_event_command(cvk_context* ctx, cvk_command* cmd,
         m_status = CL_QUEUED;
         m_command_type = cmd->type();
     }
+    if (m_command_type == CL_COMMAND_USER || !queue->use_timeline_semaphore()) {
+        m_cv = std::make_unique<cvk_std_condition_variable>();
+    } else {
+        cvk_semaphore* sem;
+        uint64_t value;
+        queue->get_next_semaphore_and_value(&sem, &value, m_command_type);
+        m_cv = std::make_unique<cvk_semaphore_condition_variable>(sem, value);
+    }
 }
 
-void cvk_event_command::set_status(cl_int status) {
-    cvk_debug("cvk_event::set_status: event = %p, status = %d", this, status);
-    std::lock_guard<std::mutex> lock(m_lock);
+void cvk_event_command::set_status_no_lock(cl_int status) {
+    if (status >= m_status)
+        return;
 
-    CVK_ASSERT(status < m_status);
+    cvk_debug("cvk_event::set_status: event = %p, status = %d", this, status);
     m_status = status;
 
     if (m_queue && m_queue->has_property(CL_QUEUE_PROFILING_ENABLE) && m_cmd &&
@@ -54,7 +62,7 @@ void cvk_event_command::set_status(cl_int status) {
         }
     }
 
-    if (completed() || terminated()) {
+    if (m_status <= 0) {
 
         for (auto& type_cb : m_callbacks) {
             for (auto& cb : type_cb.second) {
@@ -62,6 +70,6 @@ void cvk_event_command::set_status(cl_int status) {
             }
         }
 
-        m_cv.notify_all();
+        m_cv->notify();
     }
 }
diff --git a/clvk/src/event.hpp b/clvk/src/event.hpp
index 86d85d9..03d567c 100644
--- a/clvk/src/event.hpp
+++ b/clvk/src/event.hpp
@@ -17,6 +17,7 @@
 #include "cl_headers.hpp"
 #include "icd.hpp"
 #include "objects.hpp"
+#include "semaphore.hpp"
 #include "tracing.hpp"
 #include "utils.hpp"
 
@@ -34,12 +35,68 @@ struct cvk_event_callback {
     void* data;
 };
 
+struct cvk_condition_variable {
+    virtual ~cvk_condition_variable() {}
+
+    virtual void notify() = 0;
+    CHECK_RETURN virtual bool wait(std::unique_lock<std::mutex>&) = 0;
+
+    virtual cvk_semaphore* get_semaphore() {
+        CVK_ASSERT(false && "Should never be called");
+        return NULL;
+    }
+    virtual uint64_t get_value() {
+        CVK_ASSERT(false && "Should never be called");
+        return 0;
+    }
+
+    // By default, completion is managed by the user. Only timeline semaphore
+    // can have unnotified completion requiring an additionnal manual check.
+    CHECK_RETURN virtual bool is_complete() { return false; }
+};
+
+struct cvk_semaphore_condition_variable final : public cvk_condition_variable {
+    cvk_semaphore_condition_variable(cvk_semaphore* sem, uint64_t value)
+        : m_sem(sem), m_value(value) {
+        sem->retain();
+    }
+    ~cvk_semaphore_condition_variable() { m_sem->release(); }
+
+    void notify() override final { m_sem->notify(m_value); }
+    CHECK_RETURN bool wait(std::unique_lock<std::mutex>& lock) override final {
+        lock.unlock();
+        bool ret = m_sem->wait(m_value);
+        lock.lock();
+        return ret;
+    }
+
+    bool is_complete() override final { return m_sem->poll_once(m_value); }
+
+    cvk_semaphore* get_semaphore() override final { return m_sem; }
+    uint64_t get_value() override final { return m_value; }
+
+private:
+    cvk_semaphore* m_sem;
+    uint64_t m_value;
+};
+
+struct cvk_std_condition_variable final : public cvk_condition_variable {
+    void notify() override final { m_cv.notify_all(); }
+    CHECK_RETURN bool wait(std::unique_lock<std::mutex>& lock) override final {
+        m_cv.wait(lock);
+        return true;
+    }
+
+private:
+    std::condition_variable m_cv;
+};
+
 struct cvk_event : public _cl_event, api_object<object_magic::event> {
 
     cvk_event(cvk_context* ctx, cvk_command_queue* queue)
         : api_object(ctx), m_command_type(0), m_queue(queue) {}
 
-    virtual cl_int get_status() const = 0;
+    virtual cl_int get_status() = 0;
 
     bool completed() { return get_status() == CL_COMPLETE; }
 
@@ -63,6 +120,14 @@ struct cvk_event : public _cl_event, api_object<object_magic::event> {
     virtual cl_int wait() = 0 ;
 
     virtual uint64_t get_profiling_info(cl_profiling_info pinfo) const = 0 ;
+    virtual cvk_semaphore* get_semaphore() {
+        CVK_ASSERT(false && "Should never be called");
+        return nullptr;
+    }
+    virtual uint64_t get_value() {
+        CVK_ASSERT(false && "Should never be called");
+        return 0;
+    }
 
 protected:
     cl_command_type m_command_type;
@@ -73,7 +138,10 @@ struct cvk_event_command : public cvk_event {
 
     cvk_event_command(cvk_context* ctx, cvk_command* cmd, cvk_command_queue* queue);
 
-    void set_status(cl_int status) override final;
+    void set_status(cl_int status) override final {
+        std::lock_guard<std::mutex> lock(m_lock);
+        set_status_no_lock(status);
+    }
 
     void register_callback(cl_int callback_type,
                            cvk_event_callback_pointer_type ptr,
@@ -89,16 +157,33 @@ struct cvk_event_command : public cvk_event {
         }
     }
 
-    cl_int get_status() const override final { return m_status; }
+    void check_completion() {
+        std::unique_lock<std::mutex> lock(m_lock);
+        if (m_cv->is_complete()) {
+            set_status_no_lock(CL_COMPLETE);
+        }
+    }
+
+    cl_int get_status() override final {
+        check_completion();
+        return m_status;
+    }
 
     cl_int wait() override final {
         std::unique_lock<std::mutex> lock(m_lock);
         cvk_debug("cvk_event::wait: event = %p, status = %d", this, m_status);
-        if ((m_status != CL_COMPLETE) && (m_status >= 0)) {
+        if (m_status > 0) {
             TRACE_BEGIN_EVENT(command_type(), "queue", (uintptr_t)m_queue,
                               "command", (uintptr_t)m_cmd);
-            m_cv.wait(lock);
+            auto ret = m_cv->wait(lock);
             TRACE_END();
+            if (!ret) {
+                m_status = CL_EXEC_STATUS_ERROR_FOR_EVENTS_IN_WAIT_LIST;
+            }
+            // This is needed in case of timeline semaphore which mark the
+            // event as completed but have not update anything (not the
+            // status nor the profiling information)
+            set_status_no_lock(CL_COMPLETE);
         }
 
         return m_status;
@@ -128,13 +213,19 @@ struct cvk_event_command : public cvk_event {
         set_profiling_info(pinfo, sample_clock());
     }
 
+    cvk_semaphore* get_semaphore() override final {
+        return m_cv->get_semaphore();
+    }
+    uint64_t get_value() override final { return m_cv->get_value(); }
+
 private:
+    void set_status_no_lock(cl_int status);
     void execute_callback(cvk_event_callback cb) {
         cb.pointer(this, m_status, cb.data);
     }
 
     std::mutex m_lock;
-    std::condition_variable m_cv;
+    std::unique_ptr<cvk_condition_variable> m_cv;
     cl_int m_status;
     cl_ulong m_profiling_data[4]{};
     cvk_command* m_cmd;
@@ -173,7 +264,7 @@ struct cvk_event_combine : public cvk_event {
         }
     }
 
-    cl_int get_status() const override final {
+    cl_int get_status() override final {
         return std::min(m_end_event->get_status(), m_start_event->get_status());
     }
 
diff --git a/clvk/src/queue.cpp b/clvk/src/queue.cpp
index 5faa651..058ef23 100644
--- a/clvk/src/queue.cpp
+++ b/clvk/src/queue.cpp
@@ -33,11 +33,14 @@ cvk_command_queue::cvk_command_queue(
       m_properties_array(std::move(properties_array)), m_executor(nullptr),
       m_command_batch(nullptr), m_vulkan_queue(device->vulkan_queue_allocate()),
       m_command_pool(device, m_vulkan_queue.queue_family()),
+      m_semaphore_main_timeline(nullptr),
+      m_semaphore_image_init_timeline(nullptr),
       m_max_cmd_batch_size(device->get_max_cmd_batch_size()),
       m_max_first_cmd_batch_size(device->get_max_first_cmd_batch_size()),
       m_max_cmd_group_size(device->get_max_cmd_group_size()),
       m_max_first_cmd_group_size(device->get_max_first_cmd_group_size()),
-      m_nb_batch_in_flight(0), m_nb_group_in_flight(0) {
+      m_nb_batch_in_flight(0), m_nb_group_in_flight(0),
+      m_nb_synchronous_submit_command_in_flight(0) {
 
     m_groups.push_back(std::make_unique<cvk_command_group>());
 
@@ -66,6 +69,12 @@ cl_int cvk_command_queue::init() {
 }
 
 cvk_command_queue::~cvk_command_queue() {
+    if (m_semaphore_image_init_timeline != nullptr) {
+        m_semaphore_image_init_timeline->release();
+    }
+    if (m_semaphore_main_timeline != nullptr) {
+        m_semaphore_main_timeline->release();
+    }
     if (m_executor != nullptr) {
         get_thread_pool()->return_executor(m_executor);
     }
@@ -108,6 +117,23 @@ cl_int cvk_command_queue::satisfy_data_dependencies(cvk_command* cmd) {
     return CL_SUCCESS;
 }
 
+void cvk_command_queue::enqueue_command(cvk_command* cmd) {
+    TRACE_FUNCTION("queue", (uintptr_t)this, "cmd", (uintptr_t)cmd);
+    // clvk only supports inorder queues.
+    // But as the commands can be executed by 2 threads (1 executor and the main
+    // thread), we need to explicit the dependency to ensure it will be
+    // respected.
+    if (!m_groups.back()->commands.empty()) {
+        cmd->add_dependency(m_groups.back()->commands.back()->event());
+    } else if (m_finish_event != nullptr) {
+        cmd->add_dependency(m_finish_event);
+    }
+    if (cmd->is_synchronous_submit()) {
+        sync_submit_cmd_enqueued();
+    }
+    m_groups.back()->commands.push_back(cmd);
+}
+
 cl_int cvk_command_queue::enqueue_command(cvk_command* cmd, _cl_event** event) {
 
     cl_int err;
@@ -133,6 +159,9 @@ cl_int cvk_command_queue::enqueue_command(cvk_command* cmd, _cl_event** event) {
             return err;
         }
 
+        cmd->event()->set_profiling_info_from_monotonic_clock(
+            CL_PROFILING_COMMAND_QUEUED);
+
         // End command batch when size limit reached
         if (m_command_batch->batch_size() >= m_max_cmd_batch_size ||
             (m_nb_batch_in_flight == 0 &&
@@ -156,14 +185,14 @@ cl_int cvk_command_queue::enqueue_command(cvk_command* cmd, _cl_event** event) {
             }
         }
 
-        m_groups.back()->commands.push_back(cmd);
+        enqueue_command(cmd);
+
+        cmd->event()->set_profiling_info_from_monotonic_clock(
+            CL_PROFILING_COMMAND_QUEUED);
     }
 
     cvk_debug_fn("enqueued command %p, event %p", cmd, cmd->event());
 
-    cmd->event()->set_profiling_info_from_monotonic_clock(
-        CL_PROFILING_COMMAND_QUEUED);
-
     if (event != nullptr) {
         // The event will be returned to the app, retain it for the user
         cmd->event()->retain();
@@ -219,9 +248,18 @@ cl_int cvk_command_queue::end_current_command_batch() {
         if (!m_command_batch->end()) {
             return CL_OUT_OF_RESOURCES;
         }
-        m_groups.back()->commands.push_back(m_command_batch);
-        m_command_batch = nullptr;
+        enqueue_command(m_command_batch);
+
+        if (use_timeline_semaphore() &&
+            m_nb_synchronous_submit_command_in_flight == 1) {
+            m_command_batch->set_event_status(CL_SUBMITTED);
+            m_command_batch->set_event_status(CL_RUNNING);
+            if (m_command_batch->submit() != CL_COMPLETE) {
+                return CL_OUT_OF_RESOURCES;
+            }
+        }
 
+        m_command_batch = nullptr;
         batch_enqueued();
     }
     return CL_SUCCESS;
@@ -295,7 +333,7 @@ cl_int cvk_command_queue::execute_cmds_dominated_by_no_lock(
     }
 
     m_lock.unlock();
-    auto cmds = exec->extract_cmds_dominated_by(false, num_events, event_list);
+    auto cmds = exec->extract_cmds_dominated_by(true, num_events, event_list);
     auto ret = execute_cmds(cmds);
     m_lock.lock();
 
@@ -461,6 +499,27 @@ cl_int cvk_command_queue::finish() {
     return CL_SUCCESS;
 }
 
+void cvk_command_queue::get_next_semaphore_and_value(cvk_semaphore** sem,
+                                                     uint64_t* value,
+                                                     cl_command_type type) {
+    CVK_ASSERT(m_device->has_timeline_semaphore_support());
+
+    cvk_semaphore*& semaphore = type == CLVK_COMMAND_IMAGE_INIT
+                                    ? m_semaphore_image_init_timeline
+                                    : m_semaphore_main_timeline;
+    if (semaphore == nullptr) {
+        semaphore = new cvk_semaphore(this);
+    }
+
+    *sem = semaphore;
+    *value = semaphore->get_next_value();
+
+    if (*value >= m_device->maxTimelineSemaphoreValueDifference()) {
+        semaphore->release();
+        semaphore = nullptr;
+    }
+}
+
 VkResult cvk_command_pool::allocate_command_buffer(VkCommandBuffer* cmdbuf) {
 
     std::lock_guard<std::mutex> lock(m_lock);
@@ -502,6 +561,22 @@ bool cvk_command_buffer::begin() {
     return true;
 }
 
+bool cvk_command_buffer::submit(VkSemaphore signal_semaphore,
+                                uint64_t signal_value,
+                                std::vector<VkSemaphore>& wait_semaphores,
+                                std::vector<uint64_t>& wait_values) {
+    auto& queue = m_queue->vulkan_queue();
+
+    VkResult res = queue.submit(m_command_buffer, signal_semaphore,
+                                signal_value, wait_semaphores, wait_values);
+
+    if (res != VK_SUCCESS) {
+        return false;
+    }
+
+    return true;
+}
+
 bool cvk_command_buffer::submit_and_wait() {
     auto& queue = m_queue->vulkan_queue();
 
@@ -1043,12 +1118,38 @@ cl_int cvk_command_batchable::do_action() {
     return CL_COMPLETE;
 }
 
-cl_int cvk_command_batch::do_action() {
+cl_int cvk_command_batch::submit() {
+    VkSemaphore signal_semaphore = m_event->get_semaphore()->get_vk_semaphore();
+    uint64_t signal_value = m_event->get_value();
+    std::vector<VkSemaphore> wait_semaphores;
+    std::vector<uint64_t> wait_values;
+    for (auto &dep : dependencies()) {
+        wait_semaphores.push_back(dep->get_semaphore()->get_vk_semaphore());
+        wait_values.push_back(dep->get_value());
+    }
+    if (!m_command_buffer->submit(signal_semaphore, signal_value,
+                                  wait_semaphores, wait_values)) {
+        return CL_OUT_OF_RESOURCES;
+    }
+    m_submitted = true;
+    // We have consider the default case when the batch is executed
+    // synchronously. As we now know that is will be asynchronous, mark this
+    // command as completed as far as synchronous commands are concerned.
+    m_queue->sync_submit_cmd_completed();
 
-    cvk_info("executing batch of %lu commands", m_commands.size());
+    // add ourselves in dependency so that we wait on the batch completion
+    // before calling 'cvk_command_batch::do_action' in 'cvk_command::execute'.
+    add_dependency(m_event);
 
-    if (!m_command_buffer->submit_and_wait()) {
-        return CL_OUT_OF_RESOURCES;
+    return CL_COMPLETE;
+}
+
+cl_int cvk_command_batch::do_action() {
+    if (!m_submitted) {
+        cvk_info("executing batch of %lu commands", m_commands.size());
+        if (!m_command_buffer->submit_and_wait()) {
+            return CL_OUT_OF_RESOURCES;
+        }
     }
 
     m_queue->batch_completed();
diff --git a/clvk/src/queue.hpp b/clvk/src/queue.hpp
index 838bac5..b43a7ae 100644
--- a/clvk/src/queue.hpp
+++ b/clvk/src/queue.hpp
@@ -142,6 +142,11 @@ struct cvk_command_queue : public _cl_command_queue,
         return (m_properties & prop) == prop;
     }
 
+    bool use_timeline_semaphore() const {
+        return m_device->has_timeline_semaphore_support() &&
+               !has_property(CL_QUEUE_PROFILING_ENABLE);
+    }
+
     CHECK_RETURN cl_int enqueue_command_with_deps(cvk_command* cmd,
                                                   cl_uint num_dep_events,
                                                   _cl_event* const* dep_events,
@@ -200,11 +205,21 @@ struct cvk_command_queue : public _cl_command_queue,
         TRACE_CNT(group_in_flight_counter, group - 1);
     }
 
+    void sync_submit_cmd_enqueued() {
+        m_nb_synchronous_submit_command_in_flight++;
+    }
+    void sync_submit_cmd_completed() {
+        m_nb_synchronous_submit_command_in_flight--;
+    }
+
     cl_int execute_cmds_dominated_by(cl_uint num_events,
                                      _cl_event* const* event_list);
     cl_int execute_cmds_dominated_by_no_lock(cl_uint num_events,
                                              _cl_event* const* event_list);
 
+    void get_next_semaphore_and_value(cvk_semaphore** sem, uint64_t* value,
+                                      cl_command_type type);
+
 private:
     CHECK_RETURN cl_int satisfy_data_dependencies(cvk_command* cmd);
     void enqueue_command(cvk_command* cmd);
@@ -227,6 +242,9 @@ private:
     cvk_vulkan_queue_wrapper& m_vulkan_queue;
     cvk_command_pool m_command_pool;
 
+    cvk_semaphore *m_semaphore_main_timeline;
+    cvk_semaphore *m_semaphore_image_init_timeline;
+
     cl_uint m_max_cmd_batch_size;
     cl_uint m_max_first_cmd_batch_size;
     cl_uint m_max_cmd_group_size;
@@ -235,6 +253,8 @@ private:
     std::atomic<uint64_t> m_nb_batch_in_flight;
     std::atomic<uint64_t> m_nb_group_in_flight;
 
+    std::atomic<uint64_t> m_nb_synchronous_submit_command_in_flight;
+
     TRACE_CNT_VAR(batch_in_flight_counter);
     TRACE_CNT_VAR(group_in_flight_counter);
 };
@@ -321,6 +341,10 @@ struct cvk_command_buffer {
         return res == VK_SUCCESS;
     }
 
+    CHECK_RETURN bool submit(VkSemaphore signal_semaphore,
+                             uint64_t signal_value,
+                             std::vector<VkSemaphore>& wait_semaphores,
+                             std::vector<uint64_t>& wait_values);
     CHECK_RETURN bool submit_and_wait();
 
     operator VkCommandBuffer() { return m_command_buffer; }
@@ -339,7 +363,12 @@ struct cvk_command {
         : m_type(type), m_queue(queue),
           m_event(new cvk_event_command(m_queue->context(), this, queue)) {}
 
-    virtual ~cvk_command() { m_event->release(); }
+    virtual ~cvk_command() {
+        for (auto& event : m_event_deps) {
+            event->release();
+        }
+        m_event->release();
+    }
 
     void set_dependencies(cl_uint num_event_deps,
                           _cl_event* const* event_deps) {
@@ -368,6 +397,15 @@ struct cvk_command {
     // never have data movement requirements of their own.
     virtual bool is_data_movement() const { return false; }
 
+    virtual bool is_synchronous_submit() const {
+        for (auto &ev : m_event_deps) {
+            if (ev->is_user_event()) {
+                return true;
+            }
+        }
+        return false;
+    }
+
     void add_dependency(cvk_event* dep) {
         dep->retain();
         m_event_deps.push_back(dep);
@@ -381,7 +419,6 @@ struct cvk_command {
             if (ev->wait() != CL_COMPLETE) {
                 status = CL_EXEC_STATUS_ERROR_FOR_EVENTS_IN_WAIT_LIST;
             }
-            ev->release();
         }
 
         // Then execute the action if no dependencies failed
@@ -395,12 +432,15 @@ struct cvk_command {
             status = do_action();
             TRACE_END();
         }
+        if (is_synchronous_submit()){
+            m_queue->sync_submit_cmd_completed();
+        }
 
         set_event_status(status);
         return status;
     }
 
-    cvk_event_command* event() const { return m_event; }
+    virtual cvk_event_command* event() const { return m_event; }
 
     cl_command_type type() const { return m_type; }
 
@@ -628,6 +668,7 @@ struct cvk_command_batchable : public cvk_command {
 
     bool can_be_batched() const override final;
     bool is_built_before_enqueue() const override final { return false; }
+    bool is_synchronous_submit() const override final { return true; }
 
     CHECK_RETURN cl_int get_timestamp_query_results(cl_ulong* start,
                                                     cl_ulong* end);
@@ -764,7 +805,7 @@ private:
 
 struct cvk_command_batch : public cvk_command {
     cvk_command_batch(cvk_command_queue* queue)
-        : cvk_command(CLVK_COMMAND_BATCH, queue) {}
+        : cvk_command(CLVK_COMMAND_BATCH, queue), m_submitted(false) {}
 
     cl_int add_command(cvk_command_batchable* cmd) {
         if (!m_command_buffer) {
@@ -796,6 +837,8 @@ struct cvk_command_batch : public cvk_command {
 
     cl_uint batch_size() { return m_commands.size(); }
 
+    bool is_synchronous_submit() const override final { return !m_submitted; }
+
     CHECK_RETURN cl_int
     set_profiling_info(cl_profiling_info pinfo) override final {
         cl_int status = cvk_command::set_profiling_info(pinfo);
@@ -828,14 +871,24 @@ struct cvk_command_batch : public cvk_command {
 
     void set_event_status(cl_int status) override final {
         m_event->set_status(status);
+        if (status == CL_RUNNING && m_queue->profiling_on_device())
+            return;
         for (auto& cmd : m_commands) {
             cmd->set_event_status(status);
         }
     }
 
+    CHECK_RETURN cl_int submit();
+
+    cvk_event_command* event() const override final {
+        CVK_ASSERT(m_commands.size() > 0);
+        return m_commands.back()->event();
+    }
+
 private:
     CHECK_RETURN cl_int do_action() override final;
 
+    bool m_submitted;
     std::vector<std::unique_ptr<cvk_command_batchable>> m_commands;
     std::unique_ptr<cvk_command_buffer> m_command_buffer;
     cl_ulong m_sync_dev, m_sync_host;
diff --git a/clvk/src/semaphore.cpp b/clvk/src/semaphore.cpp
new file mode 100644
index 0000000..a331ab1
--- /dev/null
+++ b/clvk/src/semaphore.cpp
@@ -0,0 +1,127 @@
+// Copyright 2022 The clvk authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "semaphore.hpp"
+#include "queue.hpp"
+#include "tracing.hpp"
+
+cvk_semaphore::cvk_semaphore(cvk_command_queue* queue)
+    : m_queue((uintptr_t)queue), m_device(queue->device()), m_next_value(0),
+      m_current_value(0) {
+
+    VkSemaphoreTypeCreateInfo timelineCreateInfo;
+    timelineCreateInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+    timelineCreateInfo.pNext = NULL;
+    timelineCreateInfo.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+    timelineCreateInfo.initialValue = m_next_value;
+
+    VkSemaphoreCreateInfo createInfo;
+    createInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+    createInfo.pNext = &timelineCreateInfo;
+    createInfo.flags = 0;
+
+    vkCreateSemaphore(m_device->vulkan_device(), &createInfo, NULL, &m_sem);
+}
+cvk_semaphore::~cvk_semaphore() {
+    vkDestroySemaphore(m_device->vulkan_device(), m_sem, NULL);
+}
+
+void cvk_semaphore::notify(uint64_t value) {
+    std::unique_lock<std::mutex> lock(m_lock);
+    if (value <= m_current_value) {
+        return;
+    }
+
+    VkSemaphoreSignalInfo signalInfo;
+    signalInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO;
+    signalInfo.pNext = NULL;
+    signalInfo.semaphore = m_sem;
+    signalInfo.value = value;
+    VkResult res = vkSignalSemaphore(m_device->vulkan_device(), &signalInfo);
+    if (res != VK_SUCCESS) {
+        cvk_error("vkSignalSemaphore failed (%d %s)", res,
+                  vulkan_error_string(res));
+    }
+    m_current_value = value;
+}
+
+bool cvk_semaphore::wait(uint64_t value) {
+    std::unique_lock<std::mutex> lock(m_lock);
+    VkResult res = VK_SUCCESS;
+    do {
+        if (value <= m_current_value) {
+            return true;
+        }
+        VkSemaphoreWaitInfo waitInfo;
+        waitInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO;
+        waitInfo.pNext = NULL;
+        waitInfo.flags = 0;
+        waitInfo.semaphoreCount = 1;
+        waitInfo.pSemaphores = &m_sem;
+        waitInfo.pValues = &value;
+
+        TRACE_BEGIN("vkWaitSemaphore", "queue", m_queue);
+        m_lock.unlock();
+        res =
+            vkWaitSemaphores(m_device->vulkan_device(), &waitInfo, 1000000);
+        m_lock.lock();
+        TRACE_END();
+
+        if (res != VK_TIMEOUT && res != VK_SUCCESS) {
+            cvk_error("vkWaitSemaphores failed (%d %s)", res,
+                      vulkan_error_string(res));
+            return false;
+        }
+    } while (res != VK_SUCCESS);
+    m_current_value = std::max(m_current_value, value);
+    return true;
+}
+
+bool cvk_semaphore::poll(uint64_t value) {
+    uint64_t counter_value;
+    TRACE_BEGIN("vkPollSemaphore", "queue", m_queue);
+    do {
+        VkResult res = vkGetSemaphoreCounterValue(m_device->vulkan_device(),
+                                                  m_sem, &counter_value);
+        if (res != VK_SUCCESS) {
+            cvk_error("vkGetSemaphoreCounterValue failed (%d %s)", res,
+                      vulkan_error_string(res));
+            return false;
+        }
+    } while (counter_value < value);
+    m_lock.lock();
+    m_current_value = std::max(m_current_value, counter_value);
+    m_lock.unlock();
+    TRACE_END();
+
+    return true;
+}
+
+bool cvk_semaphore::poll_once(uint64_t value) {
+    uint64_t counter_value;
+    TRACE_BEGIN("vkPollOnceSemaphore", "queue", m_queue);
+    VkResult res = vkGetSemaphoreCounterValue(m_device->vulkan_device(), m_sem,
+                                              &counter_value);
+    if (res != VK_SUCCESS) {
+        cvk_error("vkGetSemaphoreCounterValue failed (%d %s)", res,
+                  vulkan_error_string(res));
+        return false;
+    }
+    m_lock.lock();
+    m_current_value = std::max(m_current_value, counter_value);
+    m_lock.unlock();
+    TRACE_END();
+
+    return m_current_value >= value;
+}
diff --git a/clvk/src/semaphore.hpp b/clvk/src/semaphore.hpp
new file mode 100644
index 0000000..350f422
--- /dev/null
+++ b/clvk/src/semaphore.hpp
@@ -0,0 +1,43 @@
+// Copyright 2022 The clvk authors.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#pragma once
+
+#include "utils.hpp"
+#include "device.hpp"
+
+struct cvk_command_queue;
+
+struct cvk_semaphore : public refcounted {
+    cvk_semaphore(cvk_command_queue* queue);
+    ~cvk_semaphore();
+
+    CHECK_RETURN bool poll_once(uint64_t value);
+    CHECK_RETURN bool poll(uint64_t value);
+    CHECK_RETURN bool wait(uint64_t value);
+    void notify(uint64_t value);
+
+    VkSemaphore get_vk_semaphore() { return m_sem; }
+    uint64_t get_next_value() { return ++m_next_value; }
+
+private:
+    uintptr_t m_queue;
+    cvk_device* m_device;
+    VkSemaphore m_sem;
+    uint64_t m_next_value;
+    uint64_t m_current_value;
+
+    std::mutex m_lock;
+};
+
diff --git a/clvk/src/vkutils.hpp b/clvk/src/vkutils.hpp
index b26a5bd..6ca89e5 100644
--- a/clvk/src/vkutils.hpp
+++ b/clvk/src/vkutils.hpp
@@ -64,19 +64,36 @@ struct cvk_vulkan_queue_wrapper {
         return ret;
     }
 
-    CHECK_RETURN VkResult submit(const std::vector<VkCommandBuffer>& cmdbufs) {
+    CHECK_RETURN VkResult submit(VkCommandBuffer command_buffer,
+                                 VkSemaphore signal_semaphore,
+                                 uint64_t signal_value,
+                                 std::vector<VkSemaphore>& wait_semaphores,
+                                 std::vector<uint64_t>& wait_values) {
         std::lock_guard<std::mutex> lock(m_lock);
 
+        std::vector<VkPipelineStageFlags> wait_stage_masks;
+        for (auto unused : wait_semaphores) {
+            UNUSED(unused);
+            wait_stage_masks.push_back(VK_PIPELINE_STAGE_ALL_COMMANDS_BIT);
+        }
+        VkTimelineSemaphoreSubmitInfo timelineInfo;
+        timelineInfo.sType = VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO;
+        timelineInfo.pNext = NULL;
+        timelineInfo.waitSemaphoreValueCount = (uint32_t)wait_values.size();
+        timelineInfo.pWaitSemaphoreValues = wait_values.data();
+        timelineInfo.signalSemaphoreValueCount = 1;
+        timelineInfo.pSignalSemaphoreValues = &signal_value;
+
         VkSubmitInfo submitInfo = {
             VK_STRUCTURE_TYPE_SUBMIT_INFO,
-            nullptr,
-            0,                                     // waitSemaphoreCOunt
-            nullptr,                               // pWaitSemaphores
-            nullptr,                               // pWaitDstStageMask
-            static_cast<uint32_t>(cmdbufs.size()), // commandBufferCount
-            cmdbufs.data(),
-            0,       // signalSemaphoreCount
-            nullptr, // pSignalSemaphores
+            &timelineInfo,
+            (uint32_t)wait_semaphores.size(), // waitSemaphoreCOunt
+            wait_semaphores.data(),           // pWaitSemaphores
+            wait_stage_masks.data(),          // pWaitDstStageMask
+            1,                                // commandBufferCount
+            &command_buffer,
+            1,                 // signalSemaphoreCount
+            &signal_semaphore, // pSignalSemaphores
         };
 
         TRACE_BEGIN("vkQueueSubmit");
@@ -87,6 +104,8 @@ struct cvk_vulkan_queue_wrapper {
                          vulkan_error_string(ret));
         }
 
+        m_num_submissions++;
+
         return ret;
     }
 
