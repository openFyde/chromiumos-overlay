From 30d94f33f119534029cf19b6feb11c3cc4025c52 Mon Sep 17 00:00:00 2001
From: Yiwei Zhang <zzyiwei@chromium.org>
Date: Sun, 5 Mar 2023 00:35:24 -0800
Subject: [PATCH 4/5] vkr: support asynchronous ring wait

Signed-off-by: Yiwei Zhang <zzyiwei@chromium.org>
---
 src/venus/vkr_common.h    |  1 +
 src/venus/vkr_context.c   | 67 +++++++++++++++++++++++++++++++++++++++
 src/venus/vkr_context.h   | 22 +++++++++++++
 src/venus/vkr_ring.c      |  1 +
 src/venus/vkr_ring.h      |  6 ++++
 src/venus/vkr_transport.c | 16 ++++++++++
 6 files changed, 113 insertions(+)

diff --git a/src/venus/vkr_common.h b/src/venus/vkr_common.h
index b3255e1f..c383597c 100644
--- a/src/venus/vkr_common.h
+++ b/src/venus/vkr_common.h
@@ -62,6 +62,7 @@
 
 struct vn_info_extension_table;
 struct vkr_context;
+struct vkr_ring;
 struct vkr_instance;
 struct vkr_physical_device;
 struct vkr_device;
diff --git a/src/venus/vkr_context.c b/src/venus/vkr_context.c
index 9595fd0b..55bdf88b 100644
--- a/src/venus/vkr_context.c
+++ b/src/venus/vkr_context.c
@@ -373,6 +373,45 @@ vkr_context_destroy_resource(struct vkr_context *ctx, uint32_t res_id)
    vkr_context_remove_resource(ctx, res_id);
 }
 
+static inline bool
+vkr_seqno_ge(uint32_t a, uint32_t b)
+{
+   /* a >= b, but deal with wrapping as well */
+   return (a - b) <= INT32_MAX;
+}
+
+void
+vkr_context_on_ring_seqno_update(struct vkr_context *ctx,
+                                 uint64_t ring_id,
+                                 uint64_t ring_seqno)
+{
+   mtx_lock(&ctx->wait_ring.mutex);
+   if (ctx->wait_ring.id == ring_id && vkr_seqno_ge(ring_seqno, ctx->wait_ring.seqno))
+      cnd_signal(&ctx->wait_ring.cond);
+   mtx_unlock(&ctx->wait_ring.mutex);
+}
+
+bool
+vkr_context_wait_ring_seqno(struct vkr_context *ctx,
+                            struct vkr_ring *ring,
+                            uint64_t ring_seqno)
+{
+   TRACE_FUNC();
+
+   bool ok = true;
+
+   mtx_lock(&ctx->wait_ring.mutex);
+   ctx->wait_ring.id = ring->id;
+   ctx->wait_ring.seqno = ring_seqno;
+   while (ok && !vkr_seqno_ge(vkr_ring_load_head(ring), ring_seqno)) {
+      ok = cnd_wait(&ctx->wait_ring.cond, &ctx->wait_ring.mutex) == thrd_success;
+   }
+   ctx->wait_ring.id = 0;
+   mtx_unlock(&ctx->wait_ring.mutex);
+
+   return ok;
+}
+
 static inline const char *
 vkr_context_get_name(const struct vkr_context *ctx)
 {
@@ -383,6 +422,27 @@ vkr_context_get_name(const struct vkr_context *ctx)
    return ctx->instance_name ? ctx->instance_name : ctx->debug_name;
 }
 
+static inline void
+vkr_context_wait_ring_fini(struct vkr_context *ctx)
+{
+   cnd_destroy(&ctx->wait_ring.cond);
+   mtx_destroy(&ctx->wait_ring.mutex);
+}
+
+static bool
+vkr_context_wait_ring_init(struct vkr_context *ctx)
+{
+   if (mtx_init(&ctx->wait_ring.mutex, mtx_plain) != thrd_success)
+      return false;
+
+   if (cnd_init(&ctx->wait_ring.cond) != thrd_success) {
+      mtx_destroy(&ctx->wait_ring.mutex);
+      return false;
+   }
+
+   return true;
+}
+
 void
 vkr_context_destroy(struct vkr_context *ctx)
 {
@@ -396,6 +456,8 @@ vkr_context_destroy(struct vkr_context *ctx)
    }
    mtx_destroy(&ctx->ring_mutex);
 
+   vkr_context_wait_ring_fini(ctx);
+
    if (ctx->instance) {
       vkr_log("destroying context %d (%s) with a valid instance", ctx->ctx_id,
               vkr_context_get_name(ctx));
@@ -464,6 +526,9 @@ vkr_context_create(uint32_t ctx_id,
    if (VKR_DEBUG(VALIDATE))
       ctx->validate_level = VKR_CONTEXT_VALIDATE_FULL;
 
+   if (!vkr_context_wait_ring_init(ctx))
+      goto err_ctx_wait_ring_init;
+
    if (mtx_init(&ctx->object_mutex, mtx_plain) != thrd_success)
       goto err_ctx_object_mutex;
 
@@ -503,6 +568,8 @@ err_ctx_resource_mutex:
 err_ctx_object_table:
    mtx_destroy(&ctx->object_mutex);
 err_ctx_object_mutex:
+   vkr_context_wait_ring_fini(ctx);
+err_ctx_wait_ring_init:
    free(ctx->debug_name);
 err_debug_name:
    free(ctx);
diff --git a/src/venus/vkr_context.h b/src/venus/vkr_context.h
index 07db7c33..0e6da762 100644
--- a/src/venus/vkr_context.h
+++ b/src/venus/vkr_context.h
@@ -52,6 +52,18 @@ struct vkr_context {
    mtx_t ring_mutex;
    struct list_head rings;
 
+   struct {
+      mtx_t mutex;
+      cnd_t cond;
+      uint64_t id;
+      /* This represents the ring head position to be waited on. The protocol supports
+       * 64bit seqno and we only use 32bit internally because the delta between the ring
+       * head and ring current will never exceed the ring size, which is far smaller than
+       * 32bit int limit in practice.
+       */
+      uint32_t seqno;
+   } wait_ring;
+
    mtx_t object_mutex;
    struct hash_table *object_table;
 
@@ -212,6 +224,16 @@ vkr_context_get_object(struct vkr_context *ctx, vkr_object_id obj_id)
    return likely(entry) ? entry->data : NULL;
 }
 
+void
+vkr_context_on_ring_seqno_update(struct vkr_context *ctx,
+                                 uint64_t ring_id,
+                                 uint64_t ring_seqno);
+
+bool
+vkr_context_wait_ring_seqno(struct vkr_context *ctx,
+                            struct vkr_ring *ring,
+                            uint64_t ring_seqno);
+
 void
 vkr_context_add_instance(struct vkr_context *ctx,
                          struct vkr_instance *instance,
diff --git a/src/venus/vkr_ring.c b/src/venus/vkr_ring.c
index eb548de1..1bf88fd9 100644
--- a/src/venus/vkr_ring.c
+++ b/src/venus/vkr_ring.c
@@ -226,6 +226,7 @@ vkr_ring_submit_cmd(struct vkr_ring *ring,
       /* update the ring head intra-cs to optimize ring space */
       const uint32_t cur_ring_head = ring_head + (dec->cur - buffer);
       vkr_ring_store_head(ring, cur_ring_head);
+      vkr_context_on_ring_seqno_update(ring->dispatch.data, ring->id, cur_ring_head);
    }
 
    vkr_cs_decoder_reset(dec);
diff --git a/src/venus/vkr_ring.h b/src/venus/vkr_ring.h
index c3209be6..d36e79f4 100644
--- a/src/venus/vkr_ring.h
+++ b/src/venus/vkr_ring.h
@@ -127,4 +127,10 @@ vkr_ring_submit_virtqueue_seqno(struct vkr_ring *ring, uint64_t seqno);
 bool
 vkr_ring_wait_virtqueue_seqno(struct vkr_ring *ring, uint64_t seqno);
 
+static inline uint32_t
+vkr_ring_load_head(const struct vkr_ring *ring)
+{
+   return atomic_load_explicit(ring->control.head, memory_order_acquire);
+}
+
 #endif /* VKR_RING_H */
diff --git a/src/venus/vkr_transport.c b/src/venus/vkr_transport.c
index 59af81ec..5ca1f2e7 100644
--- a/src/venus/vkr_transport.c
+++ b/src/venus/vkr_transport.c
@@ -291,6 +291,21 @@ vkr_dispatch_vkWaitVirtqueueSeqno100000MESA(
       vkr_context_set_fatal(ctx);
 }
 
+static void
+vkr_dispatch_vkWaitRingSeqno100000MESA(struct vn_dispatch_context *dispatch,
+                                       struct vn_command_vkWaitRingSeqno100000MESA *args)
+{
+   struct vkr_context *ctx = dispatch->data;
+   struct vkr_ring *ring = lookup_ring(ctx, args->ring);
+   if (!ring) {
+      vkr_context_set_fatal(ctx);
+      return;
+   }
+
+   if (!vkr_context_wait_ring_seqno(ctx, ring, args->seqno))
+      vkr_context_set_fatal(ctx);
+}
+
 static void
 vkr_dispatch_vkGetVenusExperimentalFeatureData100000MESA(
    UNUSED struct vn_dispatch_context *dispatch,
@@ -333,6 +348,7 @@ vkr_context_init_transport_dispatch(struct vkr_context *ctx)
       vkr_dispatch_vkSubmitVirtqueueSeqno100000MESA;
    dispatch->dispatch_vkWaitVirtqueueSeqno100000MESA =
       vkr_dispatch_vkWaitVirtqueueSeqno100000MESA;
+   dispatch->dispatch_vkWaitRingSeqno100000MESA = vkr_dispatch_vkWaitRingSeqno100000MESA;
 
    dispatch->dispatch_vkGetVenusExperimentalFeatureData100000MESA =
       vkr_dispatch_vkGetVenusExperimentalFeatureData100000MESA;
-- 
2.37.3

