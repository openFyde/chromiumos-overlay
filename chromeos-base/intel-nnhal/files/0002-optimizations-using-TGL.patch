From 8f2cea20b342d3bc05d09a1297264cdd78fb3231 Mon Sep 17 00:00:00 2001
From: Anisha Kulkarni
 <anisha.dattatraya.kulkarni@intel.corp-partner.google.com>
Date: Thu, 18 Feb 2021 10:58:49 -0800
Subject: [PATCH 2/2] optimizations using TGL

---
 BUILD.gn                          |   6 +
 intel_nn_hal/GnaPreparedModel.cpp | 322 ++++++++++++++++++++++--------
 intel_nn_hal/GnaPreparedModel.h   |   2 +-
 intel_nn_hal/Utils.cpp            |  45 +++++
 intel_nn_hal/Utils.h              |  22 +-
 5 files changed, 308 insertions(+), 89 deletions(-)

diff --git a/BUILD.gn b/BUILD.gn
index 4b6b25b..3855865 100755
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -63,6 +63,12 @@ shared_library("intel_nnhal") {
     "-fexceptions",
     "-fvisibility=default",
     "-DIMPLEMENT_INFERENCE_ENGINE_API",
+    "-msse4.2",
+    "-mavx512f",
+    "-march=tigerlake",
+    "-mavx512vl",
+    "-mavx512bw",
+    "-march=native",
   ]
   deps=[
     ":pugixml"
diff --git a/intel_nn_hal/GnaPreparedModel.cpp b/intel_nn_hal/GnaPreparedModel.cpp
index 65a1ca5..3b975fb 100755
--- a/intel_nn_hal/GnaPreparedModel.cpp
+++ b/intel_nn_hal/GnaPreparedModel.cpp
@@ -9,6 +9,7 @@
 #include <time.h>
 #include <chrono>
 #include <xmmintrin.h>
+#include <immintrin.h>
 
 using namespace std::chrono;
 
@@ -141,11 +142,11 @@ bool GnaPreparedModel::initialize(const hidl_vec<hidl_handle>& modelCache, const
 
     // TODO: Remove this hack to identify the nw based on operations
     int lstmCount = 0;
+    isDecoderNw = false;
     for (auto op: mModel.main.operations) {
         if (op.type == OperationType::FULLY_CONNECTED) {
             isDecoderNw = true;
             modelNameStr = "Decoder";
-            break;
         } else if (op.type == OperationType::QUANTIZED_LSTM) {
             lstmCount++;
         }
@@ -461,7 +462,7 @@ void GnaPreparedModel::deinitialize() {
                float call_units = current_units / gnaPluginPtr->noInferCall;
                // if GNA HW counters
                // get frequency of GNA module
-               float freq = 200;//getGnaFrequencyMHz();
+               float freq = getGnaFrequencyMHz();
                current_units /= freq * 1000;
                call_units /= freq;
               std::cout << std::setw(30) << std::left << counter_name.substr(4, counter_name.size() - 1);
@@ -490,17 +491,61 @@ void GnaPreparedModel::deinitialize() {
 }
 
 #ifdef PERF_COUNTERS
+#ifdef __AVX2__
 bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Shape& outputShape,
                             metrics& runtime_metrics) {
     auto start = now();
     uint32_t len = getNumberOfElements(outputShape.dimensions);
-    /* for (uint32_t i = 0; i < size; ++i) {
-        outputData[i] = static_cast<int8_t>(std::max<float>(
-                -128.0f,
-                std::min<float>(127.0f, outputShape.offset +
-                                                std::round(inputData[i] / outputShape.scale))));
-    } */
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512  m_scale =  _mm512_set1_ps(outputShape.scale);
+    const __m512  m_offset =  _mm512_set1_ps(outputShape.offset);
+
+	for ( int i = 0; i < moves; i++)
+    {
+        __m512 x = _mm512_loadu_ps(inputData);
+        __m512 div_x = _mm512_div_ps(x, m_scale);
+        __m512 add_x = _mm512_add_ps(div_x, m_offset);
+        __m512i add_x_i = _mm512_cvt_roundps_epi32(add_x, _MM_FROUND_TO_NEAREST_INT |_MM_FROUND_NO_EXC);
+        __m128i x_int =  _mm512_cvtepi32_epi8(add_x_i);
+         *((__m128i *) outputData) = x_int;
+        inputData += 16;
+        outputData += 16;
+    }
+
+    runtime_metrics.quant_time += (double(microsecondsDuration(now(), start)));
+    return true;
+}
+
+bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape& outputShape,
+                        metrics& runtime_metrics) {
+    auto start = now();
+    uint32_t len = getNumberOfElements(outputShape.dimensions);
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512 m_scale = _mm512_set1_ps(outputShape.scale);
+    const __m512 m_offset = _mm512_set1_ps(outputShape.offset);
 
+	for ( int i = 0; i < moves; i++)
+    {
+        __m512 x = _mm512_loadu_ps(inputData);
+        __m512 div_x = _mm512_div_ps(x, m_scale);
+        __m512 add_x = _mm512_add_ps(div_x, m_offset);
+        __m512i x_int = _mm512_cvtps_epi32(add_x);
+        __m256i x_int_16 = _mm512_cvtepi32_epi16(x_int);
+         *((__m256i *) outputData) = x_int_16;
+        inputData += 16;
+        outputData += 16;
+    }
+
+    runtime_metrics.quant_time += (double(microsecondsDuration(now(), start)));
+    return true;
+}
+#elif defined(__SSE4_2__)
+bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Shape& outputShape,
+                            metrics& runtime_metrics) {
+    auto start = now();
+    uint32_t len = getNumberOfElements(outputShape.dimensions);
     uint32_t moves = len >> 2;
     uint32_t mod = len % 8;
     const __m128 m_scale = _mm_set1_ps(outputShape.scale);
@@ -517,7 +562,7 @@ bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Sh
         outputData += 4;
     }
 
-    runtime_metrics.quant_time += (double(microsecondsDuration(now(), start)));
+   runtime_metrics.quant_time += (double(microsecondsDuration(now(), start)));
     return true;
 }
 
@@ -525,7 +570,6 @@ bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape
                         metrics& runtime_metrics) {
     auto start = now();
     uint32_t len = getNumberOfElements(outputShape.dimensions);
-
     uint32_t moves = len >> 2;
     uint32_t mod = len % 8;
     const __m128 m_scale = _mm_set1_ps(outputShape.scale);
@@ -540,72 +584,132 @@ bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape
          *((__m64 *) outputData) = x_int;
         inputData += 4;
         outputData += 4;
-    }/*
-    for (uint32_t i = 0; i < size; ++i) {
-        outputData[i] = static_cast<uint16_t>(outputShape.offset + (std::round(inputData[i] / outputShape.scale)));
-    } */
+    }
+
     runtime_metrics.quant_time += (double(microsecondsDuration(now(), start)));
     return true;
 }
+#endif
 
-bool deQuantize_s16(const uint8_t* inputData, const uint32_t& len, const float scale,
+template<typename T>
+bool deQuantize(const T* inputData, const uint32_t& len, const float scale,
                 const int32_t zeroPoint, float* outputData, metrics& runtime_metrics) {
+    auto start = now();
+      int32_t value;
+      for (int i = 0; i < len; ++i) {
+        value = *(inputData + i);
+        outputData[i] = static_cast<float>(scale * (value - zeroPoint));
+      }
+    auto end = now();
+    runtime_metrics.deQuant_time += (double(millisecondsDuration(end, start)));
+      return true;
+}
 
-    uint32_t moves = len >> 3;
+#ifdef __AVX2__
+template <>
+bool deQuantize(const int8_t* inputData, const uint32_t& len, const float scale,
+                const int32_t zeroPoint, float* outputData, metrics& runtime_metrics) {
+    uint32_t moves = len >> 4;
     uint32_t mod = len % 8;
-    const __m128i x0 = _mm_set1_epi16(0);
-    const __m128 m_scale = _mm_set1_ps(scale);
-
+    const __m512 m_scale = _mm512_set1_ps(scale);
+    const __m512 m_zp = _mm512_set1_ps(zeroPoint);
+    auto start = now();
 	for ( int i = 0; i < moves; i++)
     {
-        __m128i x = _mm_loadu_si128((__m128i*) inputData);
-        __m128i xlo = _mm_unpacklo_epi16(x, _mm_cmplt_epi16 (x, x0));
-        __m128i xhi = _mm_unpackhi_epi16(x, _mm_cmplt_epi16 (x, x0));
-        __m128 ylo = _mm_cvtepi32_ps(xlo);
-        __m128 yhi = _mm_cvtepi32_ps(xhi);
-        __m128 valueslo = _mm_mul_ps(ylo, m_scale);
-        __m128 valueshi = _mm_mul_ps(yhi, m_scale);
-
-        _mm_storeu_ps(outputData, valueslo);
-        _mm_storeu_ps(outputData + 4, valueshi);
-
-        outputData += 8;
+        __m128i x = _mm_load_si128((__m128i*)inputData);
+        __m512i x_256 = _mm512_cvtepi8_epi32(x);
+        __m512 y = _mm512_cvtepi32_ps(x_256);
+        __m512 y_sub = _mm512_sub_ps(y, m_zp);
+        __m512 y_mul = _mm512_mul_ps(y_sub, m_scale);
+        _mm512_storeu_ps(outputData, y_mul);
+	    outputData += 16;
         inputData += 16;
     }
+    auto end = now();
+    runtime_metrics.deQuant_time += (double(millisecondsDuration(end, start)));
+
     return true;
 }
 
-
-template<typename T>
-bool deQuantize(const uint8_t* inputData, const uint32_t& len, const float scale,
+template <>
+bool deQuantize(const uint16_t* inputData, const uint32_t& len, const float scale,
                 const int32_t zeroPoint, float* outputData, metrics& runtime_metrics) {
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512 m_scale = _mm512_set1_ps(scale);
     auto start = now();
-      int32_t value;
-      const T* inputBuf = reinterpret_cast<const T*>(inputData);
-      for (int i = 0; i < len; ++i) {
-        value = *(inputBuf + i);
-        outputData[i] = static_cast<float>(scale * (value - zeroPoint));
-      }
+    for ( int i = 0; i < moves; i++)
+    {
+        __m256i x = _mm256_loadu_epi16(inputData);
+        __m512i x_256 = _mm512_cvtepi16_epi32(x);
+        __m512 y = _mm512_cvtepi32_ps(x_256);
+        __m512 y_mul = _mm512_mul_ps(y, m_scale);
+        _mm512_storeu_ps(outputData, y_mul);
+	    outputData += 16;
+        inputData += 32;
+    }
     auto end = now();
     runtime_metrics.deQuant_time += (double(millisecondsDuration(end, start)));
-      return true;
+    return true;
 }
+#endif
+
+
 #else
-bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Shape& outputShape) {
+#ifdef __AVX2__
+bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Shape& outputShape
+                            ) {
+    uint32_t len = getNumberOfElements(outputShape.dimensions);
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512  m_scale =  _mm512_set1_ps(outputShape.scale);
+    const __m512  m_offset =  _mm512_set1_ps(outputShape.offset);
+
+    for ( int i = 0; i < moves; i++)
+    {
+        __m512 x = _mm512_loadu_ps(inputData);
+        __m512 div_x = _mm512_div_ps(x, m_scale);
+        __m512 add_x = _mm512_add_ps(div_x, m_offset);
+        __m512i add_x_i = _mm512_cvt_roundps_epi32(add_x, _MM_FROUND_TO_NEAREST_INT |_MM_FROUND_NO_EXC);
+        __m128i x_int =  _mm512_cvtepi32_epi8(add_x_i);
+         *((__m128i *) outputData) = x_int;
+        inputData += 16;
+        outputData += 16;
+    }
+
+    return true;
+}
+
+bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape& outputShape) {
     uint32_t len = getNumberOfElements(outputShape.dimensions);
-    /* for (uint32_t i = 0; i < size; ++i) {
-        outputData[i] = static_cast<int8_t>(std::max<float>(
-                -128.0f,
-                std::min<float>(127.0f, outputShape.offset +
-                                                std::round(inputData[i] / outputShape.scale))));
-    } */
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512 m_scale = _mm512_set1_ps(outputShape.scale);
+    const __m512 m_offset = _mm512_set1_ps(outputShape.offset);
+
+    for ( int i = 0; i < moves; i++)
+    {
+        __m512 x = _mm512_loadu_ps(inputData);
+        __m512 div_x = _mm512_div_ps(x, m_scale);
+        __m512 add_x = _mm512_add_ps(div_x, m_offset);
+        __m512i x_int = _mm512_cvtps_epi32(add_x);
+        __m256i x_int_16 = _mm512_cvtepi32_epi16(x_int);
+         *((__m256i *) outputData) = x_int_16;
+        inputData += 16;
+        outputData += 16;
+    }
 
+    return true;
+}
+#elif defined(__SSE4_2__)
+bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Shape& outputShape) {
+    uint32_t len = getNumberOfElements(outputShape.dimensions);
     uint32_t moves = len >> 2;
     uint32_t mod = len % 8;
     const __m128 m_scale = _mm_set1_ps(outputShape.scale);
     const __m128 m_offset = _mm_set1_ps(outputShape.offset);
 
-	for ( int i = 0; i < moves; i++)
+    for ( int i = 0; i < moves; i++)
     {
         __m128 x = _mm_loadu_ps(inputData);
         __m128 div_x = _mm_div_ps(x, m_scale);
@@ -621,13 +725,12 @@ bool quantizeToQuant8Signed(const float* inputData, int8_t* outputData, const Sh
 
 bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape& outputShape) {
     uint32_t len = getNumberOfElements(outputShape.dimensions);
-
     uint32_t moves = len >> 2;
     uint32_t mod = len % 8;
     const __m128 m_scale = _mm_set1_ps(outputShape.scale);
     const __m128 m_offset = _mm_set1_ps(outputShape.offset);
 
-	for ( int i = 0; i < moves; i++)
+    for ( int i = 0; i < moves; i++)
     {
         __m128 x = _mm_loadu_ps(inputData);
         __m128 div_x = _mm_div_ps(x, m_scale);
@@ -637,10 +740,67 @@ bool quantizeToQuant16(const float* inputData, uint16_t* outputData, const Shape
         inputData += 4;
         outputData += 4;
     }
+
+    return true;
+}
+#endif
+
+template<typename T>
+bool deQuantize(const T* inputData, const uint32_t& len, const float scale,
+                const int32_t zeroPoint, float* outputData) {
+      int32_t value;
+      for (int i = 0; i < len; ++i) {
+        value = *(inputData + i);
+        outputData[i] = static_cast<float>(scale * (value - zeroPoint));
+      }
+
+    return true;
+}
+
+#ifdef __AVX2__
+template <>
+bool deQuantize(const int8_t* inputData, const uint32_t& len, const float scale,
+                const int32_t zeroPoint, float* outputData) {
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512 m_scale = _mm512_set1_ps(scale);
+    const __m512 m_zp = _mm512_set1_ps(zeroPoint);
+	for ( int i = 0; i < moves; i++)
+    {
+        __m128i x = _mm_load_si128((__m128i*)inputData);
+        __m512i x_256 = _mm512_cvtepi8_epi32(x);
+        __m512 y = _mm512_cvtepi32_ps(x_256);
+        __m512 y_sub = _mm512_sub_ps(y, m_zp);
+        __m512 y_mul = _mm512_mul_ps(y_sub, m_scale);
+        _mm512_storeu_ps(outputData, y_mul);
+	    outputData += 16;
+        inputData += 16;
+    }
     return true;
 }
 
-bool deQuantize_s16(const uint8_t* inputData, const uint32_t& len, const float scale,
+template <>
+bool deQuantize(const uint16_t* inputData, const uint32_t& len, const float scale,
+                const int32_t zeroPoint, float* outputData) {
+    uint32_t moves = len >> 4;
+    uint32_t mod = len % 8;
+    const __m512 m_scale = _mm512_set1_ps(scale);
+    auto start = now();
+	for ( int i = 0; i < moves; i++)
+    {
+        __m256i x = _mm256_loadu_epi16(inputData);
+        __m512i x_256 = _mm512_cvtepi16_epi32(x);
+        __m512 y = _mm512_cvtepi32_ps(x_256);
+        __m512 y_mul = _mm512_mul_ps(y, m_scale);
+        _mm512_storeu_ps(outputData, y_mul);
+	    outputData += 16;
+        inputData += 32;
+    }
+    return true;
+}
+#elif defined(__SSE4_2__)
+template <>
+bool deQuantize(const uint16_t* inputData, const uint32_t& len, const float scale,
                 const int32_t zeroPoint, float* outputData) {
 
     uint32_t moves = len >> 3;
@@ -666,19 +826,7 @@ bool deQuantize_s16(const uint8_t* inputData, const uint32_t& len, const float s
     }
     return true;
 }
-
-
-template<typename T>
-bool deQuantize(const uint8_t* inputData, const uint32_t& len, const float scale,
-                const int32_t zeroPoint, float* outputData) {
-    int32_t value;
-    const T* inputBuf = reinterpret_cast<const T*>(inputData);
-    for (int i = 0; i < len; ++i) {
-        value = *(inputBuf + i);
-        outputData[i] = static_cast<float>(scale * (value - zeroPoint));
-    }
-    return true;
-}
+#endif
 #endif
 
 void GnaPreparedModel::asyncExecute(const V1_0_Request& request, MeasureTiming measure, time_point driverStart,
@@ -1478,19 +1626,19 @@ IRBlob::Ptr GnaPreparedModel::GetConstWeightsOperandAsTensor(uint32_t index)
                     blob->allocate();
 #ifdef PERF_COUNTERS
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM, 8) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics); // Ugly hack reverting
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     }
 #else
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM, 8) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>()); // Ugly hack reverting
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     }
 #endif
                 }
@@ -1603,23 +1751,23 @@ IRBlob::Ptr GnaPreparedModel::GetConstOperandAsTensor(int operand_index, int ope
                     blob->allocate();
 #ifdef PERF_COUNTERS
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_INT32) {
-                        deQuantize<int32_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int32_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     }
 #else
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_INT32) {
-                        deQuantize<int32_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int32_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     }
 #endif
                 } else {
@@ -1703,19 +1851,19 @@ Blob::Ptr GnaPreparedModel::GetInOutOperandAsBlob(RunTimeOperandInfo& op, const
                     blob->allocate();
 #ifdef PERF_COUNTERS
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>(), runtimeMetrics);
                     }
 #else
                     if (op.type == OperandType::TENSOR_QUANT8_ASYMM_SIGNED) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, op.zeroPoint, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT8_SYMM) {
-                        deQuantize<int8_t>(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int8_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     } else if (op.type == OperandType::TENSOR_QUANT16_SYMM) {
-                        deQuantize_s16(buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
+                        deQuantize((int16_t*)buf, getNumberOfElements(op.dimensions), op.scale, 0, blob->buffer().as<float*>());
                     }
 #endif
                 } else {
diff --git a/intel_nn_hal/GnaPreparedModel.h b/intel_nn_hal/GnaPreparedModel.h
index 001f607..d2e7396 100755
--- a/intel_nn_hal/GnaPreparedModel.h
+++ b/intel_nn_hal/GnaPreparedModel.h
@@ -44,7 +44,7 @@ class GnaPreparedModel : public PreparedModel {
     IRBuilder::ModelBuilder* mBuilderModel;
     GnaNetwork* gnaPluginPtr;
 
-    bool isDecoderNw, isEnc0Nw, isEnc1Nw;
+    bool isDecoderNw, isEnc0Nw, isEnc1Nw = false;
     std::string modelNameStr;
 #ifdef PERF_COUNTERS
     metrics runtimeMetrics;
diff --git a/intel_nn_hal/Utils.cpp b/intel_nn_hal/Utils.cpp
index 8a5199e..2628f46 100755
--- a/intel_nn_hal/Utils.cpp
+++ b/intel_nn_hal/Utils.cpp
@@ -564,6 +564,51 @@ std::string computeHashFromFd(int modelFd) {
     return hashString.str();
 }
 #endif
+
+#ifdef PERF_COUNTERS
+// return GNA module frequency in MHz
+float getGnaFrequencyMHz() {
+    uint32_t eax = 1;
+    uint32_t ebx = 0;
+    uint32_t ecx = 0;
+    uint32_t edx = 0;
+    uint32_t family = 0;
+    uint32_t model = 0;
+    const uint8_t sixth_family = 6;
+    const uint8_t cannon_lake_model = 102;
+    const uint8_t gemini_lake_model = 122;
+    const uint8_t ice_lake_model = 126;
+    const uint8_t tiger_lake_model = 140;
+
+    native_cpuid(&eax, &ebx, &ecx, &edx);
+    family = (eax >> 8) & 0xF;
+
+    // model is the concatenation of two fields
+    // | extended model | model |
+    // copy extended model data
+    model = (eax >> 16) & 0xF;
+    // shift
+    model <<= 4;
+    // copy model data
+    model += (eax >> 4) & 0xF;
+
+    if (family == sixth_family) {
+        switch (model) {
+            case cannon_lake_model:
+            case ice_lake_model:
+            case tiger_lake_model:
+                return 400;
+            case gemini_lake_model:
+                return 200;
+            default:
+                return 1;
+        }
+    } else {
+        // counters not supported and we returns just default value
+        return 1;
+    }
+}
+#endif
 }
 }
 }
diff --git a/intel_nn_hal/Utils.h b/intel_nn_hal/Utils.h
index 6ccfeae..e597e47 100755
--- a/intel_nn_hal/Utils.h
+++ b/intel_nn_hal/Utils.h
@@ -14,11 +14,13 @@
 #include <log/log.h>
 #include <NeuralNetworks.h>
 #include <thread>
+#include <cpuid.h>
+
 #include "ValidateHal.h"
 #include "IRBuilder.h"
 #include "Driver.h"
 
-//#define PERF_COUNTERS
+#define PERF_COUNTERS
 //#define CACHING
 //#define NN_DEBUG
 
@@ -356,6 +358,24 @@ void writeBufferToFile(std::string filename,
                         size_t length);
 
 #ifdef PERF_COUNTERS
+inline void native_cpuid(unsigned int *eax, unsigned int *ebx,
+                         unsigned int *ecx, unsigned int *edx) {
+    size_t level = *eax;
+#if defined(_WIN32) || defined(WIN32)
+    int regs[4] = {static_cast<int>(*eax), static_cast<int>(*ebx), static_cast<int>(*ecx), static_cast<int>(*edx)};
+    __cpuid(regs, level);
+    *eax = static_cast<uint32_t>(regs[0]);
+    *ebx = static_cast<uint32_t>(regs[1]);
+    *ecx = static_cast<uint32_t>(regs[2]);
+    *edx = static_cast<uint32_t>(regs[3]);
+#else
+    __get_cpuid(level, eax, ebx, ecx, edx);
+#endif
+}
+
+// return GNA module frequency in MHz
+float getGnaFrequencyMHz();
+
 typedef struct _metrics{
     double deQuant_time;
     double quant_time;
-- 
2.17.1

