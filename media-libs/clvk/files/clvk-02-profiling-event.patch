diff --git a/clvk/src/api.cpp b/clvk/src/api.cpp
index a87b5c0..7a02145 100644
--- a/clvk/src/api.cpp
+++ b/clvk/src/api.cpp
@@ -1158,8 +1158,7 @@ cl_event CLVK_API_CALL clCreateUserEvent(cl_context context,
         }
     }
 
-    auto event = new cvk_event(icd_downcast(context), CL_SUBMITTED,
-                               CL_COMMAND_USER, nullptr);
+    auto event = new cvk_event(icd_downcast(context), nullptr, nullptr);
 
     if (errcode_ret != nullptr) {
         *errcode_ret = CL_SUCCESS;
diff --git a/clvk/src/device.cpp b/clvk/src/device.cpp
index d2587c6..90e70ca 100644
--- a/clvk/src/device.cpp
+++ b/clvk/src/device.cpp
@@ -974,6 +974,8 @@ cl_int cvk_device::get_device_host_timer(cl_ulong* device_timestamp,
         vkdev, num_requested_timestamps, timestamp_infos, timestamps,
         &max_deviation);
     if (res != VK_SUCCESS) {
+        cvk_error_fn("vkGetCalibratedTimestampsEXT failed %d %s", res,
+                     vulkan_error_string(res));
         return CL_OUT_OF_RESOURCES;
     }
 
diff --git a/clvk/src/event.cpp b/clvk/src/event.cpp
index 2e9209d..79c1714 100644
--- a/clvk/src/event.cpp
+++ b/clvk/src/event.cpp
@@ -13,3 +13,56 @@
 // limitations under the License.
 
 #include "event.hpp"
+#include "queue.hpp"
+
+static const cl_profiling_info status_to_profiling_info[4] = {
+    CL_PROFILING_COMMAND_END,
+    CL_PROFILING_COMMAND_START,
+    CL_PROFILING_COMMAND_SUBMIT,
+    CL_PROFILING_COMMAND_QUEUED,
+};
+
+cvk_event::cvk_event(cvk_context* ctx, cvk_command* cmd,
+                     cvk_command_queue* queue)
+    : api_object(ctx), m_cmd(cmd), m_queue(queue) {
+    if (cmd == nullptr) {
+        m_status = CL_SUBMITTED;
+        m_command_type = CL_COMMAND_USER;
+    } else {
+        m_status = CL_QUEUED;
+        m_command_type = cmd->type();
+        set_profiling_info_from_monotonic_clock(CL_PROFILING_COMMAND_QUEUED);
+    }
+}
+
+void cvk_event::set_status(cl_int status) {
+    cvk_debug("cvk_event::set_status: event = %p, status = %d", this, status);
+    std::lock_guard<std::mutex> lock(m_lock);
+
+    CVK_ASSERT(status < m_status);
+    m_status = status;
+
+    if (m_queue && m_queue->has_property(CL_QUEUE_PROFILING_ENABLE) && m_cmd &&
+        status >= CL_COMPLETE && status <= CL_QUEUED) {
+        cl_profiling_info pinfo = status_to_profiling_info[status];
+        // profiling could have already been set. In particular in the
+        // case of the command_batch
+        if (get_profiling_info(pinfo) == 0) {
+            auto err = m_cmd->set_profiling_info(pinfo);
+            if (err != CL_SUCCESS) {
+                m_status = err;
+            }
+        }
+    }
+
+    if (completed() || terminated()) {
+
+        for (auto& type_cb : m_callbacks) {
+            for (auto& cb : type_cb.second) {
+                execute_callback(cb);
+            }
+        }
+
+        m_cv.notify_all();
+    }
+}
diff --git a/clvk/src/event.hpp b/clvk/src/event.hpp
index 167ccbd..07c2e55 100644
--- a/clvk/src/event.hpp
+++ b/clvk/src/event.hpp
@@ -23,6 +23,7 @@
 #include <mutex>
 #include <unordered_map>
 
+struct cvk_command;
 struct cvk_command_queue;
 
 using cvk_event_callback_pointer_type = void(CL_CALLBACK*)(
@@ -35,34 +36,13 @@ struct cvk_event_callback {
 
 struct cvk_event : public _cl_event, api_object<object_magic::event> {
 
-    cvk_event(cvk_context* ctx, cl_int status, cl_command_type type,
-              cvk_command_queue* queue)
-        : api_object(ctx), m_status(status), m_command_type(type),
-          m_queue(queue) {}
+    cvk_event(cvk_context* ctx, cvk_command* cmd, cvk_command_queue* queue);
 
     bool completed() { return m_status == CL_COMPLETE; }
 
     bool terminated() { return m_status < 0; }
 
-    void set_status(cl_int status) {
-        cvk_debug("cvk_event::set_status: event = %p, status = %d", this,
-                  status);
-        std::lock_guard<std::mutex> lock(m_lock);
-
-        CVK_ASSERT(status < m_status);
-        m_status = status;
-
-        if (completed() || terminated()) {
-
-            for (auto& type_cb : m_callbacks) {
-                for (auto& cb : type_cb.second) {
-                    execute_callback(cb);
-                }
-            }
-
-            m_cv.notify_all();
-        }
-    }
+    void set_status(cl_int status);
 
     void register_callback(cl_int callback_type,
                            cvk_event_callback_pointer_type ptr,
@@ -92,7 +72,8 @@ struct cvk_event : public _cl_event, api_object<object_magic::event> {
         std::unique_lock<std::mutex> lock(m_lock);
         cvk_debug("cvk_event::wait: event = %p, status = %d", this, m_status);
         if ((m_status != CL_COMPLETE) && (m_status >= 0)) {
-            TRACE_BEGIN_EVENT(m_command_type, "queue", (uintptr_t)m_queue);
+            TRACE_BEGIN_EVENT(command_type(), "queue", (uintptr_t)m_queue,
+                              "command", (uintptr_t)m_cmd);
             m_cv.wait(lock);
             TRACE_END();
         }
@@ -132,8 +113,9 @@ private:
     std::mutex m_lock;
     std::condition_variable m_cv;
     cl_int m_status;
-    cl_ulong m_profiling_data[4];
+    cl_ulong m_profiling_data[4]{};
     cl_command_type m_command_type;
+    cvk_command* m_cmd;
     cvk_command_queue* m_queue;
     std::unordered_map<cl_int, std::vector<cvk_event_callback>> m_callbacks;
 };
diff --git a/clvk/src/queue.cpp b/clvk/src/queue.cpp
index 71453ce..5eab0a4 100644
--- a/clvk/src/queue.cpp
+++ b/clvk/src/queue.cpp
@@ -161,9 +161,6 @@ cl_int cvk_command_queue::enqueue_command(cvk_command* cmd, _cl_event** event) {
 
     cvk_debug_fn("enqueued command %p, event %p", cmd, cmd->event());
 
-    cmd->event()->set_profiling_info_from_monotonic_clock(
-        CL_PROFILING_COMMAND_QUEUED);
-
     if (event != nullptr) {
         // The event will be returned to the app, retain it for the user
         cmd->event()->retain();
@@ -258,10 +255,6 @@ cl_int cvk_command_queue::wait_for_events(cl_uint num_events,
     return ret;
 }
 
-void cvk_executor_thread::set_queue(cvk_command_queue* queue) {
-    m_profiling = queue->has_property(CL_QUEUE_PROFILING_ENABLE);
-}
-
 void cvk_executor_thread::executor() {
 
     std::unique_lock<std::mutex> lock(m_lock);
@@ -269,6 +262,8 @@ void cvk_executor_thread::executor() {
     while (!m_shutdown) {
 
         if (m_groups.size() == 0) {
+            m_running = false;
+            m_running_cv.notify_all();
             TRACE_BEGIN("executor_wait");
             m_cv.wait(lock);
             TRACE_END();
@@ -293,21 +288,9 @@ void cvk_executor_thread::executor() {
             cvk_command* cmd = group->commands.front();
             cvk_debug_fn("executing command %p, event %p", cmd, cmd->event());
 
-            if (m_profiling && cmd->is_profiled_by_executor()) {
-                cmd->event()->set_profiling_info_from_monotonic_clock(
-                    CL_PROFILING_COMMAND_START);
-            }
-
             cl_int status = cmd->execute();
             cvk_debug_fn("command returned %d", status);
 
-            if (m_profiling && cmd->is_profiled_by_executor()) {
-                cmd->event()->set_profiling_info_from_monotonic_clock(
-                    CL_PROFILING_COMMAND_END);
-            }
-
-            cmd->event()->set_status(status);
-
             group->commands.pop_front();
 
             delete cmd;
@@ -348,22 +331,14 @@ cl_int cvk_command_queue::flush_no_lock() {
 
     // Set event state and profiling info
     for (auto cmd : group->commands) {
-        cmd->event()->set_status(CL_SUBMITTED);
-        if (has_property(CL_QUEUE_PROFILING_ENABLE)) {
-            cmd->event()->set_profiling_info_from_monotonic_clock(
-                CL_PROFILING_COMMAND_SUBMIT);
-        }
+        cmd->set_event_status(CL_SUBMITTED);
     }
 
     // Create execution thread if it doesn't exist
     if (m_executor == nullptr) {
-        m_executor = get_thread_pool()->get_executor(this);
+        m_executor = get_thread_pool()->get_executor();
     }
 
-    auto ev = group->commands.back()->event();
-    m_finish_event.reset(ev);
-    cvk_debug_fn("stored event %p", ev);
-
     // Submit command group to executor
     m_executor->send_group(std::move(group));
     group_sent();
@@ -380,12 +355,15 @@ cl_int cvk_command_queue::finish() {
     std::lock_guard<std::mutex> lock(m_lock);
 
     auto status = flush_no_lock();
+    if (status != CL_SUCCESS) {
+        return status;
+    }
 
-    if ((status == CL_SUCCESS) && (m_finish_event != nullptr)) {
-        m_finish_event->wait();
+    if (m_executor != nullptr) {
+        m_executor->wait_idle();
     }
 
-    return status;
+    return CL_SUCCESS;
 }
 
 VkResult cvk_command_pool::allocate_command_buffer(VkCommandBuffer* cmdbuf) {
@@ -904,7 +882,7 @@ cl_int cvk_command_batchable::build(cvk_command_buffer& command_buffer) {
 
     bool profiling = m_queue->has_property(CL_QUEUE_PROFILING_ENABLE);
 
-    if (profiling && !is_profiled_by_executor()) {
+    if (profiling && m_queue->profiling_on_device()) {
         auto vkdev = m_queue->device()->vulkan_device();
         auto res = vkCreateQueryPool(vkdev, &query_pool_create_info, nullptr,
                                      &m_query_pool);
@@ -914,7 +892,7 @@ cl_int cvk_command_batchable::build(cvk_command_buffer& command_buffer) {
     }
 
     // Sample timestamp if profiling
-    if (profiling && !is_profiled_by_executor()) {
+    if (profiling && m_queue->profiling_on_device()) {
         vkCmdResetQueryPool(command_buffer, m_query_pool, 0,
                             NUM_POOL_QUERIES_PER_COMMAND);
         vkCmdWriteTimestamp(command_buffer,
@@ -928,7 +906,7 @@ cl_int cvk_command_batchable::build(cvk_command_buffer& command_buffer) {
     }
 
     // Sample timestamp if profiling
-    if (profiling && !is_profiled_by_executor()) {
+    if (profiling && m_queue->profiling_on_device()) {
         vkCmdWriteTimestamp(command_buffer,
                             VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT, m_query_pool,
                             POOL_QUERY_CMD_END);
@@ -946,6 +924,8 @@ cl_int cvk_command_batchable::get_timestamp_query_results(cl_ulong* start,
         sizeof(timestamps), timestamps, sizeof(uint64_t),
         VK_QUERY_RESULT_64_BIT | VK_QUERY_RESULT_WAIT_BIT);
     if (res != VK_SUCCESS) {
+        cvk_error_fn("vkGetQueryPoolResults failed %d %s", res,
+                     vulkan_error_string(res));
         return CL_OUT_OF_RESOURCES;
     }
 
@@ -961,53 +941,10 @@ cl_int cvk_command_batchable::get_timestamp_query_results(cl_ulong* start,
 cl_int cvk_command_batchable::do_action() {
     CVK_ASSERT(m_command_buffer);
 
-    bool profiling = m_queue->has_property(CL_QUEUE_PROFILING_ENABLE);
-    auto dev = m_queue->device();
-
-    cl_ulong sync_host, sync_dev;
-    if (profiling && dev->has_timer_support()) {
-        if (dev->get_device_host_timer(&sync_dev, &sync_host) != CL_SUCCESS) {
-            return CL_OUT_OF_RESOURCES;
-        }
-    }
-
     if (!m_command_buffer->submit_and_wait()) {
         return CL_OUT_OF_RESOURCES;
     }
 
-    cl_int err = CL_COMPLETE;
-
-    if (profiling && m_queue->profiling_on_device()) {
-        cl_ulong start, end;
-        err = get_timestamp_query_results(&start, &end);
-        if (dev->has_timer_support()) {
-            start = dev->device_timer_to_host(start, sync_dev, sync_host);
-            end = dev->device_timer_to_host(end, sync_dev, sync_host);
-        }
-        m_event->set_profiling_info(CL_PROFILING_COMMAND_START, start);
-        m_event->set_profiling_info(CL_PROFILING_COMMAND_END, end);
-    }
-
-    return err;
-}
-
-cl_int cvk_command_batch::submit_and_wait() {
-    bool profiling = m_queue->has_property(CL_QUEUE_PROFILING_ENABLE);
-
-    if (profiling && !m_queue->profiling_on_device()) {
-        m_event->set_profiling_info_from_monotonic_clock(
-            CL_PROFILING_COMMAND_START);
-    }
-
-    if (!m_command_buffer->submit_and_wait()) {
-        return CL_OUT_OF_RESOURCES;
-    }
-
-    if (profiling && !m_queue->profiling_on_device()) {
-        m_event->set_profiling_info_from_monotonic_clock(
-            CL_PROFILING_COMMAND_END);
-    }
-
     return CL_COMPLETE;
 }
 
@@ -1015,50 +952,13 @@ cl_int cvk_command_batch::do_action() {
 
     cvk_info("executing batch of %lu commands", m_commands.size());
 
-    cl_ulong sync_host, sync_dev;
-    auto dev = m_queue->device();
-    if (dev->has_timer_support()) {
-        if (dev->get_device_host_timer(&sync_dev, &sync_host) != CL_SUCCESS) {
-            return CL_OUT_OF_RESOURCES;
-        }
+    if (!m_command_buffer->submit_and_wait()) {
+        return CL_OUT_OF_RESOURCES;
     }
-    cl_int status = submit_and_wait();
 
     m_queue->batch_completed();
 
-    bool profiling = m_queue->has_property(CL_QUEUE_PROFILING_ENABLE);
-
-    for (auto& cmd : m_commands) {
-
-        auto ev = cmd->event();
-
-        if (profiling) {
-            ev->copy_profiling_info(CL_PROFILING_COMMAND_SUBMIT, m_event);
-            if (m_queue->profiling_on_device()) {
-                cl_ulong start, end;
-                auto perr = cmd->get_timestamp_query_results(&start, &end);
-                // Report the first error if no errors were present
-                // Keep going through the events
-                if (status == CL_COMPLETE) {
-                    status = perr;
-                }
-                if (dev->has_timer_support()) {
-                    start =
-                        dev->device_timer_to_host(start, sync_dev, sync_host);
-                    end = dev->device_timer_to_host(end, sync_dev, sync_host);
-                }
-                ev->set_profiling_info(CL_PROFILING_COMMAND_START, start);
-                ev->set_profiling_info(CL_PROFILING_COMMAND_END, end);
-            } else {
-                ev->copy_profiling_info(CL_PROFILING_COMMAND_START, m_event);
-                ev->copy_profiling_info(CL_PROFILING_COMMAND_END, m_event);
-            }
-        }
-
-        ev->set_status(status);
-    }
-
-    return status;
+    return CL_COMPLETE;
 }
 
 cl_int cvk_command_buffer_host_copy::do_action() {
diff --git a/clvk/src/queue.hpp b/clvk/src/queue.hpp
index bdb0bba..7e5abbc 100644
--- a/clvk/src/queue.hpp
+++ b/clvk/src/queue.hpp
@@ -36,20 +36,33 @@ struct cvk_command_group {
 struct cvk_executor_thread {
 
     cvk_executor_thread()
-        : m_thread(nullptr), m_shutdown(false), m_profiling(false) {
+        : m_thread(nullptr), m_shutdown(false), m_running(false) {
         m_thread =
             std::make_unique<std::thread>(&cvk_executor_thread::executor, this);
     }
 
-    void set_queue(cvk_command_queue* queue);
-
     void send_group(std::unique_ptr<cvk_command_group>&& group) {
         m_lock.lock();
         m_groups.push_back(std::move(group));
         m_cv.notify_one();
+        m_running = true;
         m_lock.unlock();
     }
 
+    bool is_idle() {
+        std::unique_lock<std::mutex> lock(m_lock);
+        return !m_running;
+    }
+
+    void wait_idle() {
+        std::unique_lock<std::mutex> lock(m_lock);
+        while (m_running) {
+            TRACE_BEGIN("wait_idle");
+            m_running_cv.wait(lock);
+            TRACE_END();
+        }
+    }
+
     void shutdown() {
 
         // Tell the executor to shutdown
@@ -72,7 +85,9 @@ private:
     std::unique_ptr<std::thread> m_thread;
     bool m_shutdown;
     std::deque<std::unique_ptr<cvk_command_group>> m_groups;
-    bool m_profiling;
+
+    bool m_running;
+    std::condition_variable m_running_cv;
 };
 
 struct cvk_command_pool {
@@ -202,7 +217,6 @@ private:
     std::vector<cl_queue_properties> m_properties_array;
 
     cvk_executor_thread* m_executor;
-    cvk_event_holder m_finish_event;
 
     std::mutex m_lock;
     std::deque<std::unique_ptr<cvk_command_group>> m_groups;
@@ -239,7 +253,7 @@ struct cvk_executor_thread_pool {
         }
     }
 
-    cvk_executor_thread* get_executor(cvk_command_queue* queue) {
+    cvk_executor_thread* get_executor() {
 
         std::unique_lock<std::mutex> lock(m_lock);
 
@@ -248,20 +262,30 @@ struct cvk_executor_thread_pool {
             if (exec_state.second == executor_state::free) {
                 exec_state.second = executor_state::bound;
                 auto exec = exec_state.first;
-                exec->set_queue(queue);
+                if (!exec->is_idle()) {
+                    continue;
+                }
                 return exec;
             }
         }
 
         // No free executor found in the pool, create a new one
         cvk_executor_thread* exec = new cvk_executor_thread();
-        exec->set_queue(queue);
         m_executors[exec] = executor_state::bound;
         return exec;
     }
 
     void return_executor(cvk_executor_thread* exec) {
-        // FIXME Drain all commands before returning to the pool
+        // No need to drain all commands here.
+        // We will make sure the thread is idle before giving it to another
+        // queue.
+        //
+        // Also trying to wait_idle here can produce a deadlock.
+        // When a queue is release before the execution of all commands, the
+        // queue will be destroyed in `cvk_executor_thread::executor` when
+        // releasing the holder on the queue. But at that point, the executor
+        // will have the lock. When calling wait_idle here, we will never be
+        // able to take the lock, generating the deadlock.
         std::unique_lock<std::mutex> lock(m_lock);
 
         m_executors[exec] = executor_state::free;
@@ -312,7 +336,7 @@ struct cvk_command {
 
     cvk_command(cl_command_type type, cvk_command_queue* queue)
         : m_type(type), m_queue(queue),
-          m_event(new cvk_event(m_queue->context(), CL_QUEUED, type, queue)) {}
+          m_event(new cvk_event(m_queue->context(), this, queue)) {}
 
     virtual ~cvk_command() { m_event->release(); }
 
@@ -360,12 +384,18 @@ struct cvk_command {
         }
 
         // Then execute the action if no dependencies failed
-        if (status == CL_COMPLETE) {
-            TRACE_BEGIN_CMD(m_type, "queue", (uintptr_t) & (*m_queue));
+        if (status != CL_COMPLETE) {
+            cvk_error_fn("one or more dependencies have failed for cmd %p",
+                         this);
+        } else {
+            set_event_status(CL_RUNNING);
+            TRACE_BEGIN_CMD(m_type, "queue", (uintptr_t) & (*m_queue),
+                            "command", (uintptr_t)this);
             status = do_action();
             TRACE_END();
         }
 
+        set_event_status(status);
         return status;
     }
 
@@ -377,8 +407,6 @@ struct cvk_command {
 
     cvk_command_queue* queue() const { return m_queue; }
 
-    virtual bool is_profiled_by_executor() const { return true; }
-
     const std::vector<cvk_event*>& dependencies() const { return m_event_deps; }
 
     virtual const std::vector<cvk_mem*> memory_objects() const {
@@ -386,6 +414,15 @@ struct cvk_command {
         return {};
     }
 
+    virtual void set_event_status(cl_int status) {
+        m_event->set_status(status);
+    }
+
+    CHECK_RETURN virtual cl_int set_profiling_info(cl_profiling_info pinfo) {
+        m_event->set_profiling_info_from_monotonic_clock(pinfo);
+        return CL_SUCCESS;
+    }
+
 protected:
     cl_command_type m_type;
     cvk_command_queue_holder m_queue;
@@ -591,11 +628,6 @@ struct cvk_command_batchable : public cvk_command {
     bool can_be_batched() const override final;
     bool is_built_before_enqueue() const override final { return false; }
 
-    bool is_profiled_by_executor() const override final {
-        return !m_queue->device()->has_timer_support() &&
-               !config.queue_profiling_use_timestamp_queries;
-    }
-
     CHECK_RETURN cl_int get_timestamp_query_results(cl_ulong* start,
                                                     cl_ulong* end);
 
@@ -605,6 +637,45 @@ struct cvk_command_batchable : public cvk_command {
     build_batchable_inner(cvk_command_buffer& cmdbuf) = 0;
     CHECK_RETURN cl_int do_action() override;
 
+    CHECK_RETURN cl_int
+    set_profiling_info(cl_profiling_info pinfo) override final {
+        if (pinfo == CL_PROFILING_COMMAND_QUEUED ||
+            pinfo == CL_PROFILING_COMMAND_SUBMIT ||
+            !m_queue->profiling_on_device()) {
+            return cvk_command::set_profiling_info(pinfo);
+        } else if (pinfo == CL_PROFILING_COMMAND_START) {
+            if (m_queue->device()->has_timer_support()) {
+                auto ret = m_queue->device()->get_device_host_timer(
+                    &m_sync_dev, &m_sync_host);
+                if (ret != CL_SUCCESS)
+                    return ret;
+            }
+            return CL_SUCCESS;
+        } else {
+            CVK_ASSERT(pinfo == CL_PROFILING_COMMAND_END);
+
+            cl_ulong start, end;
+            auto perr = get_timestamp_query_results(&start, &end);
+            if (perr != CL_COMPLETE) {
+                return perr;
+            }
+            if (m_queue->device()->has_timer_support()) {
+                start = m_queue->device()->device_timer_to_host(
+                    start, m_sync_dev, m_sync_host);
+                end = m_queue->device()->device_timer_to_host(end, m_sync_dev,
+                                                              m_sync_host);
+            }
+            m_event->set_profiling_info(CL_PROFILING_COMMAND_START, start);
+            m_event->set_profiling_info(CL_PROFILING_COMMAND_END, end);
+            return CL_SUCCESS;
+        }
+    }
+
+    void set_sync_values(cl_ulong sync_dev, cl_ulong sync_host) {
+        m_sync_dev = sync_dev;
+        m_sync_host = sync_host;
+    }
+
 private:
     std::unique_ptr<cvk_command_buffer> m_command_buffer;
     VkQueryPool m_query_pool;
@@ -612,6 +683,8 @@ private:
     static const int NUM_POOL_QUERIES_PER_COMMAND = 2;
     static const int POOL_QUERY_CMD_START = 0;
     static const int POOL_QUERY_CMD_END = 1;
+
+    cl_ulong m_sync_dev, m_sync_host;
 };
 
 struct cvk_ndrange {
@@ -727,11 +800,44 @@ struct cvk_command_batch : public cvk_command {
 
     cl_uint batch_size() { return m_commands.size(); }
 
-    bool is_profiled_by_executor() const override final { return false; }
+    CHECK_RETURN cl_int
+    set_profiling_info(cl_profiling_info pinfo) override final {
+        cl_int status = cvk_command::set_profiling_info(pinfo);
+        if (m_queue->profiling_on_device()) {
+            if (pinfo == CL_PROFILING_COMMAND_START) {
+                cl_ulong sync_dev, sync_host;
+                auto ret = m_queue->device()->get_device_host_timer(&sync_dev,
+                                                                    &sync_host);
+                if (ret != CL_SUCCESS)
+                    return ret;
+                for (auto& cmd : m_commands) {
+                    cmd->set_sync_values(sync_dev, sync_host);
+                }
+            } else {
+                for (auto& cmd : m_commands) {
+                    auto err = cmd->set_profiling_info(pinfo);
+                    // do not stop at first error, but record only the first one
+                    if (err != CL_SUCCESS && status == CL_SUCCESS) {
+                        status = err;
+                    }
+                }
+            }
+        } else {
+            for (auto& cmd : m_commands) {
+                cmd->event()->copy_profiling_info(pinfo, m_event);
+            }
+        }
+        return status;
+    }
 
-private:
-    CHECK_RETURN cl_int submit_and_wait();
+    void set_event_status(cl_int status) override final {
+        m_event->set_status(status);
+        for (auto& cmd : m_commands) {
+            cmd->set_event_status(status);
+        }
+    }
 
+private:
     std::vector<std::unique_ptr<cvk_command_batchable>> m_commands;
     std::unique_ptr<cvk_command_buffer> m_command_buffer;
 };
